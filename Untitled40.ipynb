{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ab1d038-a34f-466a-9aae-d586b59ac32f",
   "metadata": {},
   "source": [
    "## Q1. What is the Filter method in feature selection, and how does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d572ace-1d8d-415c-a423-25ceb1db4359",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature Ranking: In the filter method, each feature is evaluated individually based on some statistical measure or scoring criterion. Common measures include correlation coefficients, mutual information, chi-square statistics, and information gain.\n",
    "\n",
    "Scoring Criteria: The scoring criterion used depends on the nature of the data (e.g., categorical or numerical features) and the specific problem. For example, correlation coefficients are often used for numerical features, while chi-square statistics are used for categorical features.\n",
    "\n",
    "Ranking Features: After computing the scores for each feature, they are ranked in descending order based on their scores. Features with higher scores are considered more relevant or informative.\n",
    "\n",
    "Feature Selection Threshold: A threshold may be defined to select the top-k features with the highest scores or to select features above a certain score threshold. Alternatively, all features above a certain percentile of scores may be selected.\n",
    "\n",
    "Subset Selection: Finally, the selected subset of features is used for training the machine learning model. Features that are deemed less relevant or informative are discarded.\n",
    "\n",
    "The key advantages of the filter method include simplicity, computational efficiency, and model independence. However, it may overlook interactions between features and might not necessarily lead to the optimal subset of features for a specific learning task.\n",
    "\n",
    "Here's a simplified example of using the filter method for feature selection using correlation coefficients as the scoring criterion in Python:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target\n",
    "\n",
    "# Select top 2 features using SelectKBest with f_classif scoring\n",
    "selector = SelectKBest(score_func=f_classif, k=2)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
